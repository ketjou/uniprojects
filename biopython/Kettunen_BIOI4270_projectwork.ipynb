{
 "cells": [
  {
   "source": [
    "# Project\n",
    "\n",
    "There are three tasks in this project. Each task presents a specific question for you to answer. Submit a Jupyter Notebook file that contains the code and results of your analysis. Describe your overall approach clearly in plain text. Comment your code carefully to demonstrate that you understand how to implement the analysis.\n",
    "\n",
    "Write your solutions to the given cells (see \"WRITE YOUR CODE HERE\"). Make your code print only what is requested. Select `Kernel` &rightarrow; `Restart & Clear Output` and then `Cell` &rightarrow; `Run All` from the menu before submitting your solutions, so that your submission contains clean output produced from scratch.\n",
    "\n",
    "Each task is worth 20 points. You must submit a correct and clearly documented analysis to get full points. Partial points can be obtained by successfully performing and/or documenting essential parts of the analysis. Documentation (i.e. descriptions and comments) is particularly important if your implementation is not fully correct: you can get partial points for explaining your objectives without implementing them correctly or at all.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Task 1\n",
    "\n",
    "What domain architectures do the seven known human G protein-coupled receptor kinases have? How many of each architecture are there? Print the architectures together with their counts, one per line.\n",
    "\n",
    "Suggested steps:\n",
    "- Get the proteins encoded by the GRK1 - GRK7 genes from UniProt.\n",
    "- Extract the domains from the entries.\n",
    "- Find and count the domain architectures.\n",
    "\n",
    "A domain architecture is an ordered arrangement of domains. An architecture can be printed nicely by joining its domain names with a separator, e.g. a dash.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task 1: report\n",
    "\n",
    "\n",
    "To found out the Uniprot ID's for the genes, a manual search to Uniprot.org database was done. A search with each gene name (GRK1 to GRK7) was done and with each gene the corresponding Uniprot ID was picked. \n",
    "\n",
    "#### 2.3. -21: Please see the update below the solution.\n",
    "\n",
    "These ID's were then used as a part of the search to the Uniprot mapping service. This, and all the following searches, were done with the Pythons requests module that allow user to send HTTP/1.1 requests (https://pypi.org/project/requests/).\n",
    "\n",
    "To work in a logistically efficient way, it is reasonable to get all the given genes with a on request. To achieve this, one can use the Uniprot mapping to map within the Uniprot database and get data for the given genes. However the mapping only works with Uniprot ID's and/or names\n",
    "\n",
    "The data accessed via requests was written to an XML format to be accessed locally. The file was parsed to be used in Python by using an additional module called Biopython (https://biopython.org/). Briefly described; the Biopython contains several submodules that user can use to analyze biological data. All of the analysis of this project were done using various Biopython modules.\n",
    "\n",
    "The XML file parsed with Biopythons Bio.SeqIO contains all the information of the GRK genes. The information is stored in special fields that have describing headers (features). However the downside is that when iterating the fields user might get names dublicated.  \n",
    "\n",
    "To prevent name (key) dublications and to store data in efficient way, the dictionary module of the Python was used. The name of the GRKs (as given in Uniprot) were used as keys for the dictionary and the domains of the given protein as values for the dictionary. This made possible to get a compact view of the domain architectures of the GRKs and to count the shared domains.\n",
    "\n",
    "The seven GRK's have the following domains (ordered in name + count): RGS 7, Protein kinase 7, AGC-kinase C-terminal 7 and PH 2.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get all the applications working, Python must download the module(s) of the application(s) first\n",
    "# Modules were renamed for more convenient use.\n",
    "import Bio.Align as BA\n",
    "import Bio.Align.Applications as BAA\n",
    "import Bio.AlignIO as BAIO\n",
    "import Bio.Blast.NCBIWWW as BBNW\n",
    "import Bio.Seq as BS\n",
    "import Bio.SeqRecord as BSR\n",
    "import Bio.SeqIO as BSIO\n",
    "import requests as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API address\n",
    "url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "# required parameters as dictionary\n",
    "data = {\n",
    "    # map within Uniprot, to AC/ID\n",
    "    'from': 'ACC+ID',\n",
    "    # to Uniprot AC\n",
    "    'to': 'ACC',\n",
    "    # output format is xml as domain info \n",
    "    # is needed from the info fields\n",
    "    'format': 'xml',\n",
    "    # Uniprot IDs of the seven genes\n",
    "    'query': 'Q15835 P25098 P35626 P32298 P34947 P43250 Q8WTQ7',\n",
    "    # mapping toimii: from: GENENAME to ACC+ID, organism: \"homo sapiens\"\n",
    "    # https://www.uniprot.org/help/api_idmapping\n",
    "}\n",
    "\n",
    "# send query and get response\n",
    "response = R.get(url, params=data)\n",
    "\n",
    "#save the response to a gprotdomains.xml -file\n",
    "with open('gprotdomains.xml', 'w') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following code is from example solution to ex 3.8 \n",
    "# in the course BIOI4270 provided by teacher Juho Heimonen\n",
    "\n",
    "# It is used for simplicity and for correctness, as the author\n",
    "# couldn't solve the ex 3.8 during the course\n",
    "\n",
    "\n",
    "# a new empty dictionary to collect the domain architecture\n",
    "domains = {}\n",
    "\n",
    "# as the file contains multiple entries use Bio.SeqIO.parse\n",
    "# to make an iteratable SeqRecord object\n",
    "\n",
    "for x in BSIO.parse(\"gprotdomains.xml\", \"uniprot-xml\"):\n",
    "    #start iterating with iterator x\n",
    "\n",
    "    for y in x.features:\n",
    "        #from the feature level another iteration is made\n",
    "\n",
    "        if y.type == \"domain\":\n",
    "        #if the type section in features contain word domain, do following\n",
    "\n",
    "                # check if the key (name of the protein) is not yet present\n",
    "                # in the dictionary keys\n",
    "                if not x.name in domains:\n",
    "\n",
    "                    #if naem not found (true): initalize the keys as entry names and values as empty lists\n",
    "                    domains[x.name] = []\n",
    "\n",
    "                    # inside the empty values list\n",
    "                    # append the domain descriptions for each protein\n",
    "                domains[x.name].append(y.qualifiers[\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GRK1_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal']\nARBK1_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal', 'PH']\nARBK2_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal', 'PH']\nGRK4_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal']\nGRK5_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal']\nGRK6_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal']\nGRK7_HUMAN ['RGS', 'Protein kinase', 'AGC-kinase C-terminal']\n\nRGS 7\nProtein kinase 7\nAGC-kinase C-terminal 7\nPH 2\n"
     ]
    }
   ],
   "source": [
    "# From the formatted dictionary (domains)\n",
    "for key,value in domains.items():\n",
    "    # get the domain architectures represented as key value pairs\n",
    "    # where keys are the names and the values are the domains of the gene\n",
    "    print(key,value)\n",
    "\n",
    "    # Print an empty space to give a better visibility\n",
    "print()\n",
    "\n",
    "# as the domains are in nested list, counter can't acces them straightly\n",
    "# therefore combine the entries into one list\n",
    "\n",
    "# an empty list for collecting the entries\n",
    "allDom = []\n",
    "\n",
    "# start iterating the entries --> acces the lists \n",
    "for things in domains.values():\n",
    "\n",
    "    #start iterating the key-value pairs inside lists\n",
    "        for value in things:\n",
    "\n",
    "            #append them to the empty list\n",
    "            allDom.append(value)\n",
    "\n",
    "#import automatic counter to count the occurences of the domains\n",
    "from collections import Counter\n",
    "\n",
    "# as the Counter produces a dictionary, \n",
    "# acces keys (domain names) and values (number of occurences)\n",
    "for key,value in Counter(allDom).items():\n",
    "    # and print them\n",
    "    print(key,value)"
   ]
  },
  {
   "source": [
    "### Task1 UPDATE 2.3.-21:\n",
    "\n",
    "After the Q&A session in 26.2. I realised I could've done the search by making a query with \"gene: GRK1...\" etc.\n",
    "\n",
    "I also noticed a possibility in the ID Mapping section to map with gene names to the Swissprot database. From the online server the query was a piece of cake, but for some reason I couldn't get the query to work via Python. Hence I left everything as it was.\n",
    "\n",
    "If you could have a look at my examples below and be kind enough to tell me what is wrong with them. Every time I got the query to work, I got all animalias GRK genes whilst having the filter 'organism': \"Homo sapiens (Human) [9606]\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API address\n",
    "import requests\n",
    "\n",
    "url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "# required parameters as dictionary\n",
    "data = {\n",
    "    # map with Gene names\n",
    "    'from': 'GENENAME',\n",
    "    # to Uniprot SWISSPROT\n",
    "    'to': 'SWISSPROT',\n",
    "    #'reviewed': 'yes',\n",
    "    # Uniprot IDs of the seven genes\n",
    "    'organism': \"Homo sapiens (Human) [9606]\",\n",
    "    'query': 'GRK1 GRK2 GRK3 GRK4 GRK5 GRK6 GRK7', \n",
    "    \n",
    "    # ^ that gives me every animal with GRK's\n",
    "    'format': 'xml'\n",
    "\n",
    "    #nothing: 'query': 'GRK1 GRK2 GRK3 GRK4 GRK5 GRK6 GRK7 AND organism: Homo sapiens (Human) [9606]'\n",
    "    #none 'query': 'GRK1 GRK2 GRK3 GRK4 GRK5 GRK6 GRK7 AND organism: \"Homo sapiens (Human) [9606]\"', \n",
    "    #none: 'query': '\"GRK1 GRK2 GRK3 GRK4 GRK5 GRK6 GRK7\" AND organism: \"Homo sapiens (Human) [9606]\"'\n",
    "    }\n",
    "# send query and get response\n",
    "response = requests.get(url, params=data)\n",
    "print(response.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "The human histone H3.1, H3.2, H3.3, H3.4 and H3.5 proteins have equal lengths and are mostly identical. At which alignment positions does at least one of them differ from the others? Print each such position together with its most common residue, one per line. Treat gaps as different from all residues.\n",
    "\n",
    "Suggested steps:\n",
    "- Get the UniProt entries P68431, Q71DI3, P84243, Q16695 and Q6NXT2.\n",
    "- Create a multiple sequence alignment.\n",
    "- Scan the alignment for non-100%-identical positions.\n"
   ]
  },
  {
   "source": [
    "### Task2: report\n",
    "\n",
    "Uniprot database contains the information of given gene in compact FASTA- format. The format is used to describe the nucleotide or amino acid (AA) structure in letter format, where every letter represents a single AA or nucleotide. This format can be used to make different analysis and annotations. \n",
    "\n",
    "In this task, the AA sequence was collected from the Uniprot via Biopython. The FASTAs were accessed directly and written into a separate file. \n",
    "\n",
    "To obtain the information about the similarity of the sequences, a multiple sequence alignment was done. Described extremely shortly; in the MSA the sequences are put align and a best possible similarity is tried to obtain. The similarity is calculated by different algorithms and scoring methods.\n",
    "\n",
    "Various MSA algorithms/programs exist, but in this project the MUltiple Sequence Comparison by Log-Expectation (MUSCLE) program was used. The detailled description of MUSCLE is found in https://doi.org/10.1186/1471-2105-5-113.\n",
    "\n",
    "The Biopython needs an external program to do the alignment and as said, the MUSCLE was chosen for the task. The FASTA -file containing the structures of the histones was aligned with MUSCLE and the MSA file was saved for further use. After using MUSCLE, Bio.AlignIO module was used to parse the file into Bio.Align.MultipleSeqAlignment object. From the parsed object, a Counter object from Pythons collections module was used to get the unidentical positions. The final conclusion was that from 136 positions 14 are unidentical."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "# API address\n",
    "url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "# required parameters as dictionary\n",
    "data = {\n",
    "    # map within Uniprot, to AC/ID\n",
    "    'from': 'ACC+ID',\n",
    "    # to Uniprot AC\n",
    "    'to': 'ACC',\n",
    "    # output format is fasta, as only structure was wanted\n",
    "    'format': 'fasta',\n",
    "    # Uniprot IDs of the Histones\n",
    "    'query': 'P68431 Q71DI3 P84243 Q16695 Q6NXT2',\n",
    "    #P68431, Q71DI3, P84243, Q16695 and Q6NXT2\n",
    "}\n",
    "\n",
    "# send query and get response\n",
    "response = R.get(url, params=data)\n",
    "\n",
    "#save the response to a fasta formatted file named histonefasta \n",
    "with open('histonefasta.fasta', 'w') as f:\n",
    "    f.write(response.text)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Biopython doesn't have an ability to do MSA's\n",
    "# therefore it's required to use an external program to do it \n",
    "\n",
    "# For the sake of convenience, the Muscle program was use in the exercise\n",
    "# as it was used in the lectures. \n",
    "\n",
    "# Author of this work tried (for fun) to install Clustal Omega, \n",
    "# but gave up after some time\n",
    "\n",
    "# name of the program to use (muscle)\n",
    "# runs from the same folder, no need to give addres\n",
    "program_path = 'muscle.exe'\n",
    "# check that the executable exists\n",
    "import os.path as OP\n",
    "assert OP.isfile(program_path), \"MUSCLE executable missing\"\n",
    "\n",
    "# setup MUSCLE\n",
    "# # read unaligned file and write the aligned sequences to a new file \n",
    "cmd = BAA.MuscleCommandline(cmd=program_path,\n",
    "                            input=\"histonefasta.fasta\",\n",
    "                            out=\"alignedhistones.fasta\")\n",
    "# run MUSCLE\n",
    "stdout, stderr = cmd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Position number: 25\nMost common residue: [('A', 4)]\n\nPosition number: 30\nMost common residue: [('A', 4)]\n\nPosition number: 32\nMost common residue: [('A', 3)]\n\nPosition number: 34\nMost common residue: [('G', 4)]\n\nPosition number: 37\nMost common residue: [('K', 4)]\n\nPosition number: 72\nMost common residue: [('V', 4)]\n\nPosition number: 80\nMost common residue: [('K', 4)]\n\nPosition number: 88\nMost common residue: [('S', 3)]\n\nPosition number: 90\nMost common residue: [('V', 4)]\n\nPosition number: 91\nMost common residue: [('M', 3)]\n\nPosition number: 97\nMost common residue: [('S', 3)]\n\nPosition number: 99\nMost common residue: [('A', 4)]\n\nPosition number: 105\nMost common residue: [('F', 4)]\n\nPosition number: 112\nMost common residue: [('A', 4)]\n\n"
     ]
    }
   ],
   "source": [
    "# Slightly offtopic, but it is good to eat once in a while\n",
    "# Helps to notice what one has done in silly ways\n",
    "\n",
    "# Kiitos neuvoistasi!!!\n",
    "\n",
    "# read a single alignment from a file in the FASTA format \n",
    "alignment = BAIO.read(\"alignedhistones.fasta\", \"fasta\")\n",
    "# do not parse a parsed file, like someone tried to do...\n",
    "\n",
    "# create a range of numbers starting from 0 \n",
    "# ending to the last place of the MSA\n",
    "# x represents the value and increases +1 every time\n",
    "for x in range(0,alignment.get_alignment_length()):\n",
    "    \n",
    "    # x gives the column to be splitted  \n",
    "    if 5 not in Counter(alignment[:,x]).values():\n",
    "\n",
    "        # since one knows that there are 5 genes to compare\n",
    "        # one can conclude that if the value (number of hits)\n",
    "        # is 5, sequences are identical\n",
    "        # hence one can separate the non identicals (value not 5) to be printed \n",
    "\n",
    "        # x is the index in Python, +1 to get the actual position in the sequence\n",
    "        print(\"Position number: \"+str(x+1))\n",
    "        # Handy way to get the most common residue: using Counter.most_common(1)\n",
    "        print(\"Most common residue: %s\" % Counter(alignment[:,x]).most_common(1))\n",
    "        print()\n",
    "        # String formatting to get list concatenated with string and get a space between the groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "The file `peptide.fasta` contains a hypothetical peptide sequence in the FASTA format. Based on the Gene Ontology terms associated with similar sequences in UniProt, what molecular functions could this protein have? Print the IDs of Gene Ontology terms together with their counts and human-friendly names, one per line and sorted in descending order by count.\n",
    "\n",
    "Suggested steps:\n",
    "- Run BLAST and get hits with $E < 0.001$.\n",
    "- Get the corresponding UniProt entries.\n",
    "- Collect the Gene Ontology terms from the entries.\n"
   ]
  },
  {
   "source": [
    "### Task3: report\n",
    "\n",
    "As the idea was to collect the corresponding Uniprot terms, it might be preferrable to do the BLAST against the Swissprot database. The Swissprot contains manually annotated entries in the Uniprot KB database and thus user can easily collect the Uniprot ID's straight from the query. Uniprot can handle the NCBI terms as well, but one ID might produce several hits and the NCBI ID's might have to be translated to correspond the Uniprot.\n",
    "\n",
    "To figure out previously unknown organism structure, a BLAST search is - if not the best way - but one of the best ways to collect information of the structure. BLAST method can be briefly described as a search based on scores and local alignment. Using pre-defined parameters, the BLAST slices the structure (FASTA seq) to smaller pieces and starts searching for matches from database. Then based on a scoring matrice, the algorithm calculates a score for the given match and tries to lengthen the alignment. After acquiring the \"relatives\", the BLAST then calculates score and e-value (Expect Value) for the whole alignment. (Wheeler et.al, 2007, https://www.ncbi.nlm.nih.gov/books/NBK1734/)\n",
    "\n",
    "There are various BLAST databases to use, but the Biopythons Bio.Blast.NCBIWWW module uses the NCBI's BLAST database. It is possible for the user to modify  the parameters of the search, for this project the default parameters were used. BLAST used the “blosum62” matrix to give score for the matches and word size 3 to split the sequences. To be accepted for further analysis the e-value (how likely is it that similarly scored match would come randomly) is used for filtering the hits. The range of generally used E's varies from 0.001 to 0.0000001, in this project E of 0.001 was used. (Wheeler et.al, 2007, https://www.ncbi.nlm.nih.gov/books/NBK1734/)\n",
    "\n",
    "After making the query to Swissprot, the queryfile was written to a file and saved locally for further use. To interpret the results the file was made Biopython compatible with the Bio.SearchIO module. The results were filtered and accession numbers extracted to form an Uniprot query. After using the filter e < 0.001, 10 peptides remained to be used in the Uniprot query: P0ACS5 Q9HV30 Q93CH6 Q8Z8S3 Q8ZCA8 Q8FK74 Q8XD09 P0A9G4 P0A2Q8 Q9X5V4. The Uniprot query file was again saved and parsed to Biopython compatible with Bio.SeqIO. From the parsed file, isolation of the GO terms yielded 9 unique GO terms, listed below the code.\n",
    "\n",
    "The Gene Ontology is a large database to describe the genetic functions. The Biopython doesn't support the GO per se, but the GO can be downoladed (http://purl.obolibrary.org/obo/go.obo) to be imported externally via spesific parsing method. The parsing method was given previously on the course and the go.obo file was also downoladed previously. The query to find out the molecular functions for the 10 peptides was rather simple, the GO was accessed one by one with the GO terms isolated from the Uniprot file.\n",
    "\n",
    "The evidence suggest the unknown sequence to be from a bacteria and that the peptide might have transcriptional properties. It might act as a regulator in the transcription, this is supported by the the zinc binding and protein binding abilities. \n",
    "\n",
    "As the sequence seems to be bacteria based there are few hyopthesis one can make from the Cu2+ binding abilities. The cuprous ion is not well tolerated with bacterias and is preferrably extracted from the cytoplasm to periplasm or out of the cell. When the amount of Cu2+ exceeds some spesific treshold repressor proteins bind to copper and detachs from genes encoding chaperones and P-type ATPases. This enhances the Cu2+ elimination and proofens the bacterias livability. (Festa & Thiele, 2011, https://doi.org/10.1016/j.cub.2011.09.040) \n",
    "\n",
    "Based on the gathered evidence from bacteria origin to transcription activites/DNA binding abilites and cuprous binding ablities, I'd make a hypothesis this unknown sequence to act as repressor protein for genes involved to cuprous ion elimination in bacteria.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "with open('peptide.fasta') as f:\n",
    "    fasta = f.read()\n",
    "    query = fasta\n",
    "\n",
    "    \n",
    "# BLAST program to use\n",
    "program = \"blastp\"\n",
    "# database to search against\n",
    "database = \"swissprot\"\n",
    "# query sequence as a Seq object (the read fasta)\n",
    "query = query\n",
    "\n",
    "\n",
    "handle = BBNW.qblast(program, database, query)\n",
    "with open('blastedPeptides.blast', 'w') as f:\n",
    "    f.write(handle.read())\n",
    "    "
   ],
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequences in original: 26\nSequences in filtered: 10\n"
     ]
    }
   ],
   "source": [
    "# for some reason Bio Search IO import had to be here\n",
    "# didn't work fron the start\n",
    "import Bio.SearchIO as BSeIO\n",
    "\n",
    "# determining the filter: e < 0.001\n",
    "fn  = lambda hsp: hsp.evalue < 0.001\n",
    "\n",
    "# open the file\n",
    "# parse a query result into a QueryResult object\n",
    "with open('blastedPeptides.blast') as f:\n",
    "    for result in BSeIO.parse(f, 'blast-xml'):\n",
    "        print(\"Sequences in original: %s\" % len(result))\n",
    "        # print the number of seq and exit the loop\n",
    "        \n",
    "# make a new file containing only the filtered results\n",
    "result_filtered = result.hsp_filter(fn)\n",
    "# print how many seq's are left\n",
    "print(\"Sequences in filtered: %s\" % len(result_filtered))\n",
    "# haltime info to see that things have changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "P0ACS5 Q9HV30 Q93CH6 Q8Z8S3 Q8ZCA8 Q8FK74 Q8XD09 P0A9G4 P0A2Q8 Q9X5V4\n"
     ]
    }
   ],
   "source": [
    "# take the ID's from the accession field \n",
    "# and append them to a new list\n",
    "accessions = []\n",
    "for hit in result_filtered:\n",
    "    accessions.append(hit.accession)\n",
    "\n",
    "# take the accession numbers from list and join them with space\n",
    "# Uniprot only allows space separated IDs\n",
    "query = \" \".join(accessions)\n",
    "print(query)\n",
    "# just for halftime info about what we are searching"
   ]
  },
  {
   "source": [
    "import requests as R\n",
    "# form an Uniprot query\n",
    "\n",
    "# API address\n",
    "url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "# required parameters as dictionary\n",
    "data = {\n",
    "    # map within Uniprot, to AC/ID\n",
    "    'from': 'ACC+ID',\n",
    "    # to Uniprot AC\n",
    "    'to': 'ACC',\n",
    "    # output format is xml as GO info from dbxrefs is needed\n",
    "    'format': 'xml',\n",
    "    # variable query contains the ID's to search\n",
    "    'query': query,\n",
    "   \n",
    "}\n",
    "\n",
    "# send query and get response\n",
    "response = R.get(url, params=data)\n",
    "\n",
    "#save the response to a mysteryGO.xml -file\n",
    "with open('mysteryGO.xml', 'w') as f:\n",
    "    f.write(response.text)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is from example solution to ex 4.2 \n",
    "# in the course BIOI4270 provided by teacher Juho Heimonen\n",
    "\n",
    "# It is used for simplicity and for correctness, as the solution \n",
    "# that the author made to the 4.2 was longer and possibly erroneous\n",
    "\n",
    "# again had to re-import the modules\n",
    "import Bio.SeqIO as BSqIO\n",
    "import GOtools as GOT \n",
    "go = GOT.parse_go_obo('go.obo')\n",
    "\n",
    "# init an empty list to gather the terms\n",
    "molfun = []\n",
    "\n",
    "# open the previously downloaded file and make a BSIO object of it\n",
    "\n",
    "for rec in BSqIO.parse(\"mysteryGO.xml\", \"uniprot-xml\"):\n",
    "\n",
    "# start iteration from the dbxref section that contains\n",
    "# the additional info, including GO terms\n",
    "    for ref in rec.dbxrefs:\n",
    "    # see if the iteratable item starts with GO:\n",
    "        if ref.startswith(\"GO:\"):\n",
    "        # variable takes letters starting from\n",
    "        # python index 3, as they are format GO:GO...\n",
    "            item = ref[3:]\n",
    "        # finally check if the namespace of the GO entry\n",
    "        # is molecular_function (area of interest)      \n",
    "            if(go[item].namespace == 'molecular_function'):\n",
    "                # and if True, append to the list\n",
    "                molfun.append(item)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ID: GO:0003700 | Name: DNA-binding transcription factor activity | Occurences: 9\nID: GO:0005507 | Name: copper ion binding | Occurences: 8\nID: GO:0003677 | Name: DNA binding | Occurences: 7\nID: GO:0000986 | Name: bacterial-type cis-regulatory region sequence-specific DNA binding | Occurences: 2\nID: GO:0001216 | Name: DNA-binding transcription activator activity | Occurences: 2\nID: GO:0000976 | Name: transcription regulatory region sequence-specific DNA binding | Occurences: 2\nID: GO:0008270 | Name: zinc ion binding | Occurences: 1\nID: GO:0042802 | Name: identical protein binding | Occurences: 1\nID: GO:0045340 | Name: mercury ion binding | Occurences: 1\n"
     ]
    }
   ],
   "source": [
    "# import counter to get the number of occurences\n",
    "from collections import Counter\n",
    "\n",
    "# make a new list by implementing the Counter.most_common\n",
    "# conditions are left empty --> sorts and returns all terms with occurences \n",
    "sortMolfun = Counter(molfun).most_common()\n",
    "\n",
    "# create numbers between 0 and length of the sorted list\n",
    "for x in range(0,len(sortMolfun)):\n",
    "    # use that number to retrieve the info from GO and get the occurences of given position\n",
    "    print(\"ID:\", sortMolfun[x][0], \"| Name:\", go[sortMolfun[x][0]].name, \"| Occurences:\", str(sortMolfun[x][1]))\n",
    "    # ...[x][0] for GO's and ...[x][1] for numbers\n",
    "    # use the sorted info to get things in right order\n",
    "    \n",
    "    # finally figured out that you can use comma in Pyton print()\n",
    "    # better now than never"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}