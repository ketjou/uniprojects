{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises - week 3\n",
    "\n",
    "Write your solutions to the given cells (see \"WRITE YOUR CODE HERE\"). Make your code print only what is requested. Select `Kernel` &rightarrow; `Restart & Clear Output` and then `Cell` &rightarrow; `Run All` from the menu before submitting your solutions, so that your submission contains clean output produced from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1\n",
    "\n",
    "Download the entry P0A183 from UniProt in the XML format and save it to a file named `P0A183.xml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as C\n",
    "import requests as R\n",
    "import Bio.SeqIO as BSIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://www.uniprot.org/uniprot/%s.%s\"\n",
    "uid = 'P0A183'\n",
    "fmt = 'xml'\n",
    "\n",
    "url = base%(uid, fmt)\n",
    "response = R.get(url)\n",
    "\n",
    "# save record to file\n",
    "with open('P0A183.xml', 'w') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2\n",
    "\n",
    "Print the following information from the UniProt entry P0A183, one per line:\n",
    "\n",
    "- entry name\n",
    "- peptide length\n",
    "- number of $\\alpha$-helices\n",
    "- number of metal ion-binding sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entry name: MERR_PSEAI\n",
      " Number of features: 144\n",
      " Number of ùõº-helices: 3\n",
      " Number of metal ion-binding sites: 6\n"
     ]
    }
   ],
   "source": [
    "metal = 0\n",
    "alpha = 0\n",
    "for rec in BSIO.parse(\"P0A183.xml\", \"uniprot-xml\"):\n",
    "    for feature in rec.features:\n",
    "        #see if the feature type is metal ion-binding site\n",
    "        if feature.type == \"metal ion-binding site\":\n",
    "            # if so, increase counter by 1\n",
    "            metal = metal+1\n",
    "        #see if the feature type is helix    \n",
    "        elif feature.type == \"helix\":\n",
    "            # if so, increase counter by 1\n",
    "            alpha = alpha+1\n",
    "\n",
    "print(\" Entry name: %s\\n Number of features: %i\\n Number of ùõº-helices: %i\\n Number of metal ion-binding sites: %i\" \n",
    "          % (record.name, (len(rec.seq)), metal, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3\n",
    "\n",
    "The file `exercise-33.ids` contains the IDs of several UniProt entries. Fetch the sequences of those entries and write them to a file named `exercise-33.fasta` in the FASTA format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.uniprot.org/uniprot/?query=yourlist%3AM20210129A94466D2655679D1FD8953E075198DA83AAE45F&format=fasta\n"
     ]
    }
   ],
   "source": [
    "with open(\"exercise-33.ids\", 'r') as f:\n",
    "    myNames = f.read()\n",
    "\n",
    "import re\n",
    "myNames = re.sub('\\s+',' ',myNames)\n",
    "#print(myNames)\n",
    "#This might have been an additional step, as the uniprot approves a file as well\n",
    "#Anycase, decided to test how this could be done (reading to a single string)\n",
    "\n",
    "\n",
    "# Took some time to figure out what to use as a query parameters\n",
    "# Luckily the UniProt shows in the searchbar the parameters to use, once you see that they are there\n",
    "# yourlist:M20210129A94466D2655679D1FD8953E075198DA83AAE45F \n",
    "\n",
    "\n",
    "# API address\n",
    "url = \"https://www.uniprot.org/uniprot\"\n",
    "\n",
    "# required parameters as dictionary\n",
    "data = {\n",
    "    # Formed the query by uploading the ID's to uniprot for it to make a search query\n",
    "    # Don't know is this the canonical way, but works rather smoothly\n",
    "    \n",
    "    # BTW: nice to meet the carbonic anhydrases again!\n",
    "    'query': 'yourlist:M20210129A94466D2655679D1FD8953E075198DA83AAE45F',\n",
    "    # output in FASTA format\n",
    "    'format': 'fasta',\n",
    "}\n",
    "\n",
    "# send query and get response\n",
    "response = R.get(url, params=data)\n",
    "# and write it to a file\n",
    "with open('exercise-33.fasta', 'w') as f:\n",
    "    f.write(response.text)\n",
    "    \n",
    "    \n",
    "# Just to see I managed to do something right\n",
    "print(response.url)\n",
    "# show raw file content\n",
    "#with open('exercise-33.fasta') as f:\n",
    " #   print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.4\n",
    "\n",
    "Search UniProt for manually annotated entries in which the protein name matches the string \"gamma interferon\". Print the IDs of those entries, one per line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q13555\n",
      "P37231\n",
      "P15260\n",
      "Q14116\n",
      "P78344\n",
      "P38484\n",
      "Q00978\n",
      "P01579\n",
      "Q9Y6K9\n",
      "Q16666\n",
      "Q06323\n",
      "P16885\n",
      "P13236\n",
      "P53567\n",
      "P05067\n",
      "P63261\n",
      "P13284\n",
      "Q07325\n",
      "Q92637\n",
      "P12314\n",
      "P02778\n",
      "O14625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.uniprot.org/uniprot\"\n",
    "\n",
    "data = {\n",
    "    'query': 'reviewed:yes AND name:gamma interferon AND organism:\"Homo sapiens (Human) [9606]\"',\n",
    "    # output as list of IDs\n",
    "    'format': 'list',\n",
    "}\n",
    "\n",
    "response = R.get(url, params=data)\n",
    "# store raw data to variable\n",
    "ids = response.text\n",
    "\n",
    "# show output string\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.5\n",
    "\n",
    "Search UniProt for manually annotated entries that concern proteins produced by genes named \"merR\". Fetch and print the following information in a tabular format.\n",
    "\n",
    "- entry name\n",
    "- organism\n",
    "- peptide length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organism\tEntry name\tLength\n",
      "Salmonella typhimurium (strain SL1344)\tMLRA_SALTS\t243\n",
      "Escherichia coli (strain K12)\tMLRA_ECOLI\t243\n",
      "Salmonella typhimurium (strain LT2 / SGSC1412 / ATCC 700720)\tMLRA_SALTY\t243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.uniprot.org/uniprot\"\n",
    "\n",
    "data = {\n",
    "    'query': 'reviewed:yes AND name:merR',\n",
    "    # output as list of IDs\n",
    "    'format': 'tab',\n",
    "    'columns': 'organism,entry name,length',\n",
    "}\n",
    "\n",
    "response = R.get(url, params=data)\n",
    "# store raw data to variable\n",
    "merR = response.text\n",
    "\n",
    "# show output string\n",
    "print(merR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.6\n",
    "\n",
    "Parse the output of the previous exercise into a dictionary such that the keys are entry names and the values are named tuples containing the fetched data.\n",
    "\n",
    "Print the key-value pairs, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It was going bit too well to this point. Read the lectures r-e-a-l-l-y c-a-r-e-f-u-l-l-y but didn't get this\n",
    "# Googled for help, actually tweaked the data, but nothing\n",
    "# Here below you can see what I tried to do, I have two fields full of different fails\n",
    "# Eventually I got out ?tuples? and made 3 dictionaries from them\n",
    "# And must say I'm damn glad that I even got them out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 3; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-159b5f40b8ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mnewKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m# keywords on nyt lista, joka sis√§lt√§√§ kaikki tiedot, jotka p√§ivit√§n tuplesiin manuaalisesti\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-159b5f40b8ea>\u001b[0m in \u001b[0;36mConvert\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mConvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mres_dct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dictionary update sequence element #0 has length 3; 2 is required"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# split raw data into rows\n",
    "rows = merR.strip().split('\\n')\n",
    "# remove the header row\n",
    "#headers=[rows[0]]\n",
    "\n",
    "#import re\n",
    "headers = [re.sub('\\t+',' ',rows[0])]\n",
    "#print(headers)\n",
    "\n",
    "\n",
    "# Is it truly so that Entry doesn't allow spaces or lists used as name?\n",
    "\n",
    "Entry = C.namedtuple('Entry', ['Organism', 'Entryname', 'Length'])\n",
    "\n",
    "\n",
    "rows = rows[1:]\n",
    "\n",
    "keywords = []\n",
    "for row in rows:\n",
    "    # split row into fields\n",
    "    # (UniProt uses <TAB> as separator)\n",
    "    fields = row.split('\\t')\n",
    "    keywords.append(fields)\n",
    "\n",
    "newKey = Convert(keywords)\n",
    "# keywords on nyt lista, joka sis√§lt√§√§ kaikki tiedot, jotka p√§ivit√§n tuplesiin manuaalisesti\n",
    "\n",
    "# En saanut onnistunumaan, mutta olsiko onnistunut jollain alla olevalla\n",
    "\n",
    "# for(i in(len(keywords)):\n",
    "#    Entry(*keywords)\n",
    "\n",
    "record = Entry(*keywords[0])\n",
    "record2 = Entry(*keywords[1])\n",
    "record3 = Entry(*keywords[2])\n",
    "\n",
    "# Luin dokumentaatiota ja huomasin, ett√§ tuplesin saa muutettua sanakirjaksi\n",
    "print(record._asdict())\n",
    "print(record2._asdict())\n",
    "print(record3._asdict())\n",
    "\n",
    "print(newKey)\n",
    "# Vimeisimp√§n√§ yrityksen√§ yritin sulauttaa n√§m√§ sanakirja yhteen, mutta ei siit√§ mit√§√§n tullut, alapuolen\n",
    "# kent√§ss√§ n√§et yritykset\n",
    "\n",
    "\n",
    "# Olisi kaiketi voinut yritt√§√§ tehd√§ sanakirjaa siten, ett√§ kirjoittaa avainten olevan valmiiksi nuo otsikon sanat\n",
    "# Ja sitten p√§ivitt√§√§ arvot noista tupleista tai manuaalisesti kirjoittaisi kaikki\n",
    "# Mutten n√§e sen olleen ratkaisu t√§h√§n teht√§v√§√§n, pakkohan sen on jotenkin \"automaattisesti\" hoitua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dicts = [record, record2, record3]\n",
    "#new_dict = {}\n",
    "\n",
    "#for d in dicts:\n",
    " #   for k, v in d.items():\n",
    "  #      if {new_dict.keys()}:\n",
    "   #         new_dict[k] = new_dict[k] + v\n",
    "    #    else:\n",
    "     #       new_dict[k] = v\n",
    "\n",
    "#for key, value in record2.items():\n",
    "    #record.setdefault(key, []).extend(value)\n",
    "\n",
    "#def merge_two_dicts(x, y):\n",
    "    #z = x.copy()   # start with x's keys and values\n",
    "    #z.update(y)    # modifies z with y's keys and values & returns None\n",
    "   # return z\n",
    "\n",
    "#merge_two_dicts(record, record2)\n",
    "\n",
    "\n",
    "#myDict = dict(zip(headers, keywords))\n",
    "#print(myDict)\n",
    "\n",
    "\n",
    "#with open('merR.txt', 'w') as f:\n",
    " #   f.write(response.text)\n",
    "#token = open('merR.txt','r')\n",
    "#linestoken=token.readlines()\n",
    "#tokens_column_number = 0\n",
    "#resulttoken=[]\n",
    "#for x in linestoken:\n",
    " #   resulttoken.append(x.split()[tokens_column_number])\n",
    "    #tokens_column_number = tokens_column_number +1\n",
    "#token.close()\n",
    "#print(resulttoken)\n",
    "\n",
    "# p._fields            # view the field names\n",
    "#('x', 'y')\n",
    "\n",
    "#Color = namedtuple('Color', 'red green blue')\n",
    "#Pixel = namedtuple('Pixel', Point._fields + Color._fields)\n",
    "#Pixel(11, 22, 128, 255, 0)\n",
    "#Pixel(x=11, y=22, red=128, green=255, blue=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.7\n",
    "\n",
    "Search UniProt for catalytically active human carbonic anhydrases. Print the IDs of those entries, one per line.\n",
    "\n",
    "(There are exactly twelve entries. Only consider the Swiss-Prot section of UniProtKB.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P23280\n",
      "P00915\n",
      "P00918\n",
      "Q9ULX7\n",
      "P22748\n",
      "P07451\n",
      "Q8N1Q1\n",
      "Q9Y2D0\n",
      "Q16790\n",
      "P35218\n",
      "O43570\n",
      "P43166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.uniprot.org/uniprot\"\n",
    "\n",
    "# Is this cheating?\n",
    "# Designed the query in Uniprot and then blasted it to here \n",
    "data = {\n",
    "    'query': 'mnemonic:cah* organism:\"homo sapiens\" name:\"carbonic anhydrase\" active:yes NOT name:\"carbonic anhydrase-related protein\" AND reviewed:yes',\n",
    "    # output as list of IDs\n",
    "    'format': 'list',\n",
    "}\n",
    "\n",
    "response = R.get(url, params=data)\n",
    "# store raw data to variable\n",
    "ids = response.text\n",
    "# show output string\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.8\n",
    "\n",
    "Use the UniProt ID mapping service to map the UniProt entry IDs given in the file `exercise-38.ids` to NCBI RefSeq Protein entry IDs. Produce a dictionary where the keys are UniProt IDs and the values are lists of RefSeq Protein IDs. (Note that one UniProt entry may be mapped to several RefSeq Protein entries.)\n",
    "\n",
    "Print the key-value pairs, one per line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GID8_HUMAN CC110_HUMAN FA50A_HUMAN CCNJ_HUMAN IN35_HUMAN BRAT1_HUMAN TCP1L_HUMAN TEX37_HUMAN \n"
     ]
    }
   ],
   "source": [
    "# Open the file, read it and get the ID's for mapping\n",
    "\n",
    "with open(\"exercise-38.ids\", 'r') as f:\n",
    "    mapIDs = f.read()\n",
    "\n",
    "import re\n",
    "mapIDs = re.sub('\\s+',' ',mapIDs)\n",
    "print(mapIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From\tTo\n",
      "GID8_HUMAN\tNP_060366.1\n",
      "CC110_HUMAN\tNP_689988.1\n",
      "CC110_HUMAN\tNP_001138883.1\n",
      "FA50A_HUMAN\tNP_004690.1\n",
      "CCNJ_HUMAN\tNP_061957.2\n",
      "CCNJ_HUMAN\tNP_001127848.1\n",
      "CCNJ_HUMAN\tNP_001127847.1\n",
      "CCNJ_HUMAN\tXP_011538187.1\n",
      "IN35_HUMAN\tNP_001317159.1\n",
      "IN35_HUMAN\tNP_005524.2\n",
      "BRAT1_HUMAN\tNP_689956.2\n",
      "TCP1L_HUMAN\tNP_653260.1\n",
      "TEX37_HUMAN\tNP_689883.1\n",
      "TEX37_HUMAN\tXP_005264245.3\n",
      "TEX37_HUMAN\tXP_011530993.1\n",
      "TEX37_HUMAN\tXP_011530994.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "data = {\n",
    "    # map within UniProt\n",
    "    'from': 'ACC+ID',\n",
    "    'to': 'P_REFSEQ_AC',\n",
    "    # output ID's in tab format\n",
    "    'format': 'tab',\n",
    "    'query': mapIDs,\n",
    "}\n",
    "\n",
    "response = R.get(url, params=data)\n",
    "# store raw data to variable and see that they have arrived\n",
    "mapped = response.text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GID8_HUMAN': 'NP_060366.1'}\n",
      "{'CC110_HUMAN': 'NP_689988.1'}\n",
      "{'CC110_HUMAN': 'NP_001138883.1'}\n",
      "{'FA50A_HUMAN': 'NP_004690.1'}\n",
      "{'CCNJ_HUMAN': 'NP_061957.2'}\n",
      "{'CCNJ_HUMAN': 'NP_001127848.1'}\n",
      "{'CCNJ_HUMAN': 'NP_001127847.1'}\n",
      "{'CCNJ_HUMAN': 'XP_011538187.1'}\n",
      "{'IN35_HUMAN': 'NP_001317159.1'}\n",
      "{'IN35_HUMAN': 'NP_005524.2'}\n",
      "{'BRAT1_HUMAN': 'NP_689956.2'}\n",
      "{'TCP1L_HUMAN': 'NP_653260.1'}\n",
      "{'TEX37_HUMAN': 'NP_689883.1'}\n",
      "{'TEX37_HUMAN': 'XP_005264245.3'}\n",
      "{'TEX37_HUMAN': 'XP_011530993.1'}\n",
      "{'TEX37_HUMAN': 'XP_011530994.1'}\n"
     ]
    }
   ],
   "source": [
    "# Mit√§ t√§h√§n viimeiseen osaan tulee, t√§m√§n ratkaisu ei ole oikea, mutta onpahan suuntaa-antava\n",
    "# L√∂ysin kivan koodip√§tk√§n https://www.geeksforgeeks.org/python-convert-a-list-to-dictionary/\n",
    "# Ja laitoin sen tuohon luuppiin\n",
    "# Nyth√§n minulla ei varsinaisesti ole sanakirjaa, mutta tuo koodinp√§tk√§ saa n√§ytt√§m√§√§n silt√§\n",
    "\n",
    "def Convert(a):\n",
    "    it = iter(a)\n",
    "    res_dct = dict(zip(it, it))\n",
    "    return res_dct\n",
    "\n",
    "# split raw data into rows\n",
    "rows = mapped.strip().split('\\n')\n",
    "# remove the header row\n",
    "rows = rows[1:]\n",
    "\n",
    "for row in rows:\n",
    "    # split row into fields\n",
    "    # (UniProt uses <TAB> as separator)\n",
    "    fields = row.split('\\t')\n",
    "    #print(fields[0])\n",
    "    print(Convert(fields))\n",
    "    # at each round print list in dictionary format\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
